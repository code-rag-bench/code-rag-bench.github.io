<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CodeRAG-Bench: Can Retrieval Augment Code Generation?">
  <meta name="keywords" content="retrieval-augmented code generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CodeRAG-Bench: Can Retrieval Augment Code Generation?</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CodeRAG-Bench: Can Retrieval Augment Code Generation?</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zorazrw.github.io">Zora Zhiruo Wang</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://akariasai.github.io">Akari Asai</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://velocitycavalry.github.io">Xinyan Velocity Yu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://frankxfz.me/">Frank F. Xu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yiqingxyq.github.io/">Yiqing Xie</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.phontron.com/">Graham Neubig</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://dpfried.github.io/">Daniel Fried</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Carnegie Mellon University,</span>
            <span class="author-block"><sup>2</sup>University of Washington,</span>
            <span class="author-block"><sup>3</sup>University of Southern California</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.14497"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/code-rag-bench/code-rag-bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/code-rag-bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="static/images/code_rag_teaser.png" alt="CodeRAG Bench.">
        <br>
        <br>
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Many programs are challenging for language models (LMs) to generate using their parametric
            knowledge alone, yet most works generate programs solely based on problem descriptions.
            Given the success of retrieval-augmented generation in many text-oriented tasks, providing
            external resources such as library documentation or tutorials can facilitate code generation
            as well. Despite a few efforts on this, retrieval-augmented code generation (RACG) is still
            under-explored on various tasks and retrieval sources.
          </p>
          <p>
            In this work, we conduct a systematic, large-scale analysis by asking:
            <i>in what scenarios can current retrievers benefit code generation models? and what challenges do they have?</i>
            We first curate a comprehensive evaluation benchmark, CodeRAG-Bench, encompassing three
            categories of code generation tasks, including general programming, open-domain, and
            repository-level problems. We also aggregate documents from five sources for models to
            retrieve contexts from: competition solutions, online tutorials, library documentation,
            StackOverflow posts, and GitHub repositories.
          </p>
          <p>
            We examine top-performing models on CodeRAG-Bench by providing contexts retrieved from each
            or multiple sources. Although high-quality contexts can benefit code generation, current
            retrieval models often struggle to fetch useful contexts, and generation models minimally
            improve when having limited context lengths or RAG abilities. We hope the community uses
            CodeRAG-Bench as an effective testbed and continues to build better code-oriented RAG
            systems to leverage the full power of RACG.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">CodeRAG-Bench</h2>
          <div class="content has-text-justified">
            <p>
            <b>CodeRAG-Bench</b> is designed to enable rigorous evaluations and advance research on retrieval-augmented code generation. CodeRAG-Bench has some unique characteristics:
            <ul>
              <li><b>Diverse tasks:</b>CodeRAG-Bench consists of eight diverse coding taks including general programming (e.g., <a href="https://github.com/openai/human-eval">HumanEval</a>, <a href="https://livecodebench.github.io/">LiveCodeBench</a>), open-domain programming (e.g., <a href="https://code-eval.github.io/">ODEX</a>) and repository-level programming (e.g., <a href="https://www.swebench.com/">SWEBench</a>).</li>
              <li><b>Rigorous and reproducible evaluation:</b> We provide high-quality annotation of ground-truth documents to enable reliable retrieval evaluations, and for final code rag performance, we use  execution-based evaluation to asks to rigorouslly measure functional correctness.</li>
              <li><b>Unified interface:</b>our codebase provides a unified interface for retrieval, augmented generation, and evaluations. We support diverse libraries and APIs for retrieval and LM inferences, so that you can easily test new models via <a href="https://sbert.net/">sentence-transformer</a>, <a href="https://huggingface.co/docs/transformers/en/index">huggingface transformer</a>, and proprietry APIs including <a href="https://platform.openai.com/docs/overview">OpenAI API</a>, <a href="https://docs.voyageai.com/docs/introduction">Voyage AI API</a></li>
            </ul>
            </p>
            <img src="static/images/code_rag_bench_overview.png" alt="CodeRAG-Bench overview.">
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </section>
  </div>
    <!--/ Abstract. -->
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results and Analysis</h2>
          <div class="content has-text-justified">
            <p>
            <b>CodeRAG-Bench</b> is the first large-scale code retrieval and RAG benchmark that consists of diverse programing tasks and heterogeneous retrieval sources collected from Github, StackExchange, Tutorials and existing programming solutions.
          </p>
          <h4 class="title is-3">Retrieval results</h4>
          <p>
            We found that while larger retrieval models often show superior performance, still <b>retrieval performance is limited on more challenging tasks</b> like DS-1000, ODEX and SWE-Bench, which may limit code RAG effectiveness.
          </p>
          <p>
            Larger embedding models such as <a href="https://huggingface.co/Salesforce/SFR-Embedding-Mistral">SFR-Mistral</a> or Open AI embedding models also show significant increase of inference latency or index size.
          </p>
          <img src="static/images/code_rag_bench_retrieval_result.png" alt="CodeRAG-Bench overview.">
          </div>
          <div class="content has-text-justified">
          <h4 class="title is-3">Generation results (with gold document)</h4>
          <p>
            We found that if gold documents are provided, <b>most of the models including GPT-4 or GPT-3.5 (ChatGPT) can get significant gains on diverse tasks</b> including general programing as well as repository level coding.
          </p>
          <img src="static/images/code_rag_bench_generation_result.png" alt="CodeRAG-Bench overview.">
          </div>
          <div class="content has-text-justified">
            <h4 class="title is-3">RAG with canonical datastore</h4>
            <p>
            When we evaluate end-to-end RAG performance combining state-of-the-art generation and retrieval models, we see major improvements while in some tasks, we also observe <b>gap between oracle retrieval and current model retrieval</b>.
            </p>
            <p>
              <b>Some models including DeepSeekCoder benefit less from retrieval at inference time</b>, suggesting that there is space for improvements to optimize code LMs for RAG scenarios.
              </p>
            <img src="static/images/code_rag_rag_results.png" alt="CodeRAG-Bench overview.">
            </div>
            <div class="content has-text-justified">
              <h4 class="title is-3">RAG with open datastore</h4>
              <p>
                We found <b>in many coding tasks, retrieving from a larger, diverse datastore can give significant gains even on top of state-of-the-art GPT-4.</b>
                This implies that while currently many code RAG only uses canonical data store (e.g., target repository), retrieving from larger datastore consisting of documents from different sources could further unlock the effectiveness of code RAG.
              </p>
              <img src="static/images/code_rag_bench_api_rag.png" alt="CodeRAG-Bench overview.">
              </div>
        </div>
      </div>
      <!--/ Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Reprduction and Leaderboard</h2>
          <div class="content has-text-justified">
            <p>
            <b>CodeRAG-Bench</b> code is available at <a href="https://github.com/code-rag-bench/code-rag-bench">Github</a>, and all resources are available at <a href="https://huggingface.co/code-rag-bench">Huggingface Space</a>.
            </p>
            <p>
              Instructions to submit to the CodeRAG-Bench leaderboard will be available soon on Github.
              </p>
          </div>
        </div>
      </div>
    </section>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2024coderagbench,
  author = {Wang, Zora Z. and Asai, Akari and Yu, Xinyan V. and Xu, Frank F. and Xie, Yiqing and Neubig, Graham and Fried, Daniel},
  title  = {CodeRAG-Bench: Can Retrieval Augment Code Generation?},
  year   = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Template adopted from the <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies project</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
